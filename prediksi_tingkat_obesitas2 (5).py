# -*- coding: utf-8 -*-
"""bengkod uas.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cmUt2VIZAGh0V6X_49_LqKhvapb0cdgI
"""

pip install streamlit

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import streamlit as st
from imblearn.over_sampling import SMOTE
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix

# Judul aplikasi
st.title("Aplikasi Prediksi Tingkat Obesitas")

# Deskripsi aplikasi
st.markdown("""
Aplikasi ini digunakan untuk memprediksi tingkat obesitas berdasarkan data yang dimasukkan.
Silakan isi informasi berikut:
""")

# Muat dataset
data = pd.read_csv('ObesityDataSet.csv') #

# --- Pra-pemrosesan Data (Dijalankan sekali) ---
# Koersi kolom bermasalah menjadi numerik, mengatur kesalahan menjadi NaN
columns_to_coerce = ['Age', 'Height', 'Weight', 'FCVC', 'NCP', 'CH2O', 'FAF']
for col in columns_to_coerce:
    data[col] = pd.to_numeric(data[col], errors='coerce')

# Tangani nilai yang hilang dengan mengisi median for numerical columns
numeric_cols = data.select_dtypes(include=np.number).columns
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].median())

# Tangani duplikat
data.drop_duplicates(inplace=True)

# Tangani outlier menggunakan IQR for 'Weight' column
Q1_weight = data['Weight'].quantile(0.25)
Q3_weight = data['Weight'].quantile(0.75)
IQR_weight = Q3_weight - Q1_weight
data = data[(data['Weight'] >= (Q1_weight - 1.5 * IQR_weight)) & (data['Weight'] <= (Q3_weight + 1.5 * IQR_weight))]

# Convert categorical data to numerical data using one-hot encoding
data_processed = pd.get_dummies(data, drop_first=True)

# Tentukan fitur dan target
target_columns = [col for col in data_processed.columns if col.startswith('NObeyesdad_')]
features = data_processed.drop(columns=target_columns)

# Buat seri target tunggal dari kolom one-hot encoded untuk SMOTE
target_series_for_smote = data_processed[target_columns].idxmax(axis=1).apply(lambda x: x.replace('NObeyesdad_', ''))


# Tangani ketidakseimbangan kelas menggunakan SMOTE
smote = SMOTE(random_state=42)
features_resampled, target_resampled = smote.fit_resample(features, target_series_for_smote)

# Standarisasi data
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features_resampled)

# Bagi data
X_train, X_test, y_train, y_test = train_test_split(features_scaled, target_resampled, test_size=0.2, random_state=42)

# --- Pelatihan Model (Dijalankan sekali saat aplikasi dimulai) ---
# Initialize models
models = {
    'Logistic Regression': LogisticRegression(max_iter=1000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'SVM': SVC(random_state=42)
}

# Train all models and store them for later use
trained_models = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    trained_models[name] = model

# Hyperparameter tuning for Random Forest (simplified for brevity, typically done offline)
param_grid = {
    'n_estimators': [50, 100],
    'max_depth': [None, 10, 20],
}
grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3)
grid_search.fit(X_train, y_train)
best_model = grid_search.best_estimator_
trained_models['Best Random Forest (Tuned)'] = best_model
# --- End of Model Training ---

# Input data untuk prediksi
st.header("Input Data")
age = st.number_input("Usia (tahun)", min_value=0, max_value=120, value=25)
gender = st.selectbox("Jenis Kelamin", ["Male", "Female"], index=0)
height = st.number_input("Tinggi Badan (m)", min_value=0.5, max_value=2.5, value=1.70)
weight = st.number_input("Berat Badan (kg)", min_value=30, max_value=250, value=70)
family_history = st.selectbox("Apakah ada riwayat keluarga yang mengalami kelebihan berat badan?", ["Ya", "Tidak"], index=0)
FAVC = st.selectbox("Sering mengonsumsi makanan tinggi kalori?", ["Ya", "Tidak"], index=0)
FCVC = st.number_input("Frekuensi mengonsumsi sayuran (dalam sekali makan)", min_value=1, max_value=5, value=2)
NCP = st.number_input("Jumlah makan besar dalam sehari", min_value=1, max_value=10, value=3)
SMOKE = st.selectbox("Apakah Anda merokok?", ["Ya", "Tidak"], index=1)
CH2O = st.number_input("Jumlah air yang Anda minum setiap hari (liter)", min_value=0.5, max_value=5.0, value=2.0)
FAF = st.number_input("Frekuensi aktivitas fisik (dalam sekali seminggu)", min_value=0, max_value=7, value=1)
CAEC = st.selectbox("Konsumsi makanan antara waktu makan utama", ["Always", "Frequently", "Sometimes", "no"], index=2)
MTRANS = st.selectbox("Transportasi utama", ["Public_Transportation", "Automobile", "Walking", "Motorbike", "Bike"], index=0)

# Buat DataFrame input untuk prediksi
input_data = pd.DataFrame([[
    age, gender, height, weight, family_history, FAVC, FCVC, NCP, SMOKE, CH2O, FAF, CAEC, MTRANS
]], columns=[
    'Age', 'Gender', 'Height', 'Weight', 'family_history_with_overweight', 'FAVC',
    'FCVC', 'NCP', 'SMOKE', 'CH2O', 'FAF', 'CAEC', 'MTRANS'
])

# Apply one-hot encoding to input data, ensuring consistent columns with training data
all_training_features_columns = features.columns.tolist()
input_data_processed = pd.get_dummies(input_data)

# Add missing columns with 0 and drop extra columns to match the training data features
for col in all_training_features_columns:
    if col not in input_data_processed.columns:
        input_data_processed[col] = 0
for col in input_data_processed.columns:
    if col not in all_training_features_columns:
        input_data_processed = input_data_processed.drop(columns=[col])

input_data_processed = input_data_processed[all_training_features_columns]


# Scale the input data
input_data_scaled = scaler.transform(input_data_processed)

# Button to predict
if st.button("Prediksi"):
    # Use the best trained model for prediction
    prediction = trained_models['Best Random Forest (Tuned)'].predict(input_data_scaled)[0]
    st.success(f"Hasil Prediksi: {prediction}")

# Visualisasi
st.header("Visualisasi Data")
st.markdown("""
Berikut adalah visualisasi data yang dapat membantu Anda memahami distribusi tingkat obesitas.
""")

# Visualisasi distribusi target
plt.figure(figsize=(10, 5))
sns.countplot(x=target_series_for_smote)
plt.title('Distribusi Tingkat Obesitas (Setelah SMOTE)')
plt.xticks(rotation=45)
st.pyplot(plt)

# Visualisasi outlier dengan boxplot
plt.figure(figsize=(12, 6))
sns.boxplot(data=data[numeric_cols], orient='h')
plt.title('Boxplot for Outlier Detection (After Preprocessing)')
st.pyplot(plt)

# Display data description
st.header("Deskripsi Data")
st.write(data.describe())

# Visualize model performance comparison
st.header("Model Performance Comparison")

# Accuracy before tuning
accuracies_before = {name: model.score(X_test, y_test) for name, model in trained_models.items() if 'Best' not in name}

plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracies_before.keys()), y=list(accuracies_before.values()))
plt.title('Model Accuracy Before Hyperparameter Tuning')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=45)
st.pyplot(plt)

# Accuracy after tuning
accuracies_after = {'Best Random Forest (Tuned)': trained_models['Best Random Forest (Tuned)'].score(X_test, y_test)}

plt.figure(figsize=(10, 5))
sns.barplot(x=list(accuracies_after.keys()), y=list(accuracies_after.values()))
plt.title('Model Accuracy After Hyperparameter Tuning')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=45)
st.pyplot(plt)

# Combine accuracies before and after tuning for a combined plot
combined_accuracies = {**accuracies_before, **accuracies_after}

plt.figure(figsize=(12, 6))
sns.barplot(x=list(combined_accuracies.keys()), y=list(combined_accuracies.values()))
plt.title('Model Accuracy Comparison Before and After Hyperparameter Tuning')
plt.ylabel('Accuracy')
plt.ylim(0, 1)
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
st.pyplot(plt)

# Conclusion
st.header("Kesimpulan")
st.markdown("""
Aplikasi ini memberikan estimasi tingkat obesitas berdasarkan input yang diberikan.
Silakan masukkan data Anda untuk melihat hasil prediksi.
""")